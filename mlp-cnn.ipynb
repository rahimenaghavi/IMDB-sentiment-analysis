{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled44.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhJvdiDELDKs",
        "outputId": "6a50cb39-c4f5-4403-8678-1e7b5920efd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from matplotlib import pyplot\n",
        "# load the dataset\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
        "X = numpy.concatenate((X_train, X_test), axis=0)\n",
        "y = numpy.concatenate((y_train, y_test), axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training data: \")\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "5a1OD-CuLJqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e837f1d-6495-4419-9093-f860fc26e4bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: \n",
            "(50000,)\n",
            "(50000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classes: \")\n",
        "print(numpy.unique(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF6LwnWZjwDK",
        "outputId": "abdc973a-b34c-485b-9d0e-f50b27325d08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: \n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of words: \")\n",
        "print(len(numpy.unique(numpy.hstack(X))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73Sn4L_skZZW",
        "outputId": "f76244f6-f678-4e91-f4a2-c03c94a69a81"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words: \n",
            "88585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Review length: \")\n",
        "result = [len(x) for x in X]\n",
        "print(\"Mean %.2f words (%f)\" % (numpy.mean(result), numpy.std(result)))\n",
        "pyplot.subplot(121)\n",
        "pyplot.boxplot(result)\n",
        "pyplot.subplot(122)\n",
        "pyplot.hist(result)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "thUFvq0TkfKX",
        "outputId": "378cad41-75ea-43c5-ba01-82da0352610b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review length: \n",
            "Mean 234.76 words (172.911495)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**MLP**"
      ],
      "metadata": {
        "id": "dIB706s-k7Da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence"
      ],
      "metadata": {
        "id": "mr1KIZhFknC7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "#Only Load the Top 5,000 words in the IMDB Review.\n",
        "imdb.load_data(num_words=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsLOUPzwlC17",
        "outputId": "29230999-77fd-41ea-a7bb-de63dc7c8d91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
              "         list([1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "         list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 2, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "         ...,\n",
              "         list([1, 11, 6, 230, 245, 2, 9, 6, 1225, 446, 2, 45, 2174, 84, 2, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 2, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 2, 5, 4241, 18, 4, 2, 2, 250, 11, 1818, 2, 4, 4217, 2, 747, 1115, 372, 1890, 1006, 541, 2, 7, 4, 59, 2, 4, 3586, 2]),\n",
              "         list([1, 1446, 2, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "         list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 2, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 2, 2, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 2, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "        dtype=object), array([1, 0, 0, ..., 0, 1, 0])),\n",
              " (array([list([1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 1668, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]),\n",
              "         list([1, 14, 22, 3443, 6, 176, 7, 2, 88, 12, 2679, 23, 1310, 5, 109, 943, 4, 114, 9, 55, 606, 5, 111, 7, 4, 139, 193, 273, 23, 4, 172, 270, 11, 2, 2, 4, 2, 2801, 109, 1603, 21, 4, 22, 3861, 8, 6, 1193, 1330, 10, 10, 4, 105, 987, 35, 841, 2, 19, 861, 1074, 5, 1987, 2, 45, 55, 221, 15, 670, 2, 526, 14, 1069, 4, 405, 5, 2438, 7, 27, 85, 108, 131, 4, 2, 2, 3884, 405, 9, 3523, 133, 5, 50, 13, 104, 51, 66, 166, 14, 22, 157, 9, 4, 530, 239, 34, 2, 2801, 45, 407, 31, 7, 41, 3778, 105, 21, 59, 299, 12, 38, 950, 5, 4521, 15, 45, 629, 488, 2733, 127, 6, 52, 292, 17, 4, 2, 185, 132, 1988, 2, 1799, 488, 2693, 47, 6, 392, 173, 4, 2, 4378, 270, 2352, 4, 1500, 7, 4, 65, 55, 73, 11, 346, 14, 20, 9, 6, 976, 2078, 7, 2, 861, 2, 5, 4182, 30, 3127, 2, 56, 4, 841, 5, 990, 692, 8, 4, 1669, 398, 229, 10, 10, 13, 2822, 670, 2, 14, 9, 31, 7, 27, 111, 108, 15, 2033, 19, 2, 1429, 875, 551, 14, 22, 9, 1193, 21, 45, 4829, 5, 45, 252, 8, 2, 6, 565, 921, 3639, 39, 4, 529, 48, 25, 181, 8, 67, 35, 1732, 22, 49, 238, 60, 135, 1162, 14, 9, 290, 4, 58, 10, 10, 472, 45, 55, 878, 8, 169, 11, 374, 2, 25, 203, 28, 8, 818, 12, 125, 4, 3077]),\n",
              "         list([1, 111, 748, 4368, 1133, 2, 2, 4, 87, 1551, 1262, 7, 31, 318, 2, 7, 4, 498, 2, 748, 63, 29, 2, 220, 686, 2, 5, 17, 12, 575, 220, 2507, 17, 6, 185, 132, 2, 16, 53, 928, 11, 2, 74, 4, 438, 21, 27, 2, 589, 8, 22, 107, 2, 2, 997, 1638, 8, 35, 2076, 2, 11, 22, 231, 54, 29, 1706, 29, 100, 2, 2425, 34, 2, 2, 2, 5, 2, 98, 31, 2122, 33, 6, 58, 14, 3808, 1638, 8, 4, 365, 7, 2789, 3761, 356, 346, 4, 2, 1060, 63, 29, 93, 11, 2, 11, 2, 33, 6, 58, 54, 1270, 431, 748, 7, 32, 2580, 16, 11, 94, 2, 10, 10, 4, 993, 2, 7, 4, 1766, 2634, 2164, 2, 8, 847, 8, 1450, 121, 31, 7, 27, 86, 2663, 2, 16, 6, 465, 993, 2006, 2, 573, 17, 2, 42, 4, 2, 37, 473, 6, 711, 6, 2, 7, 328, 212, 70, 30, 258, 11, 220, 32, 7, 108, 21, 133, 12, 9, 55, 465, 849, 3711, 53, 33, 2071, 1969, 37, 70, 1144, 4, 2, 1409, 74, 476, 37, 62, 91, 1329, 169, 4, 1330, 2, 146, 655, 2212, 5, 258, 12, 184, 2, 546, 5, 849, 2, 7, 4, 22, 1436, 18, 631, 1386, 797, 7, 4, 2, 71, 348, 425, 4320, 1061, 19, 2, 5, 2, 11, 661, 8, 339, 2, 4, 2455, 2, 7, 4, 1962, 10, 10, 263, 787, 9, 270, 11, 6, 2, 4, 2, 2, 121, 4, 2, 26, 4434, 19, 68, 1372, 5, 28, 446, 6, 318, 2, 8, 67, 51, 36, 70, 81, 8, 4392, 2294, 36, 1197, 8, 2, 2, 18, 6, 711, 4, 2, 26, 2, 1125, 11, 14, 636, 720, 12, 426, 28, 77, 776, 8, 97, 38, 111, 2, 2, 168, 1239, 2, 137, 2, 18, 27, 173, 9, 2399, 17, 6, 2, 428, 2, 232, 11, 4, 2, 37, 272, 40, 2708, 247, 30, 656, 6, 2, 54, 2, 3292, 98, 6, 2840, 40, 558, 37, 2, 98, 4, 2, 1197, 15, 14, 9, 57, 4893, 5, 4659, 6, 275, 711, 2, 2, 3292, 98, 6, 2, 10, 10, 2, 19, 14, 2, 267, 162, 711, 37, 2, 752, 98, 4, 2, 2378, 90, 19, 6, 2, 7, 2, 1810, 2, 4, 4770, 3183, 930, 8, 508, 90, 4, 1317, 8, 4, 2, 17, 2, 3965, 1853, 4, 1494, 8, 4468, 189, 4, 2, 2, 2, 4, 4770, 5, 95, 271, 23, 6, 2, 2, 2, 2, 33, 1526, 6, 425, 3155, 2, 4535, 1636, 7, 4, 4669, 2, 469, 4, 4552, 54, 4, 150, 2, 2, 280, 53, 2, 2, 18, 339, 29, 1978, 27, 2, 5, 2, 68, 1830, 19, 2, 2, 4, 1515, 7, 263, 65, 2132, 34, 6, 2, 2, 43, 159, 29, 9, 4706, 9, 387, 73, 195, 584, 10, 10, 1069, 4, 58, 810, 54, 14, 2, 117, 22, 16, 93, 5, 1069, 4, 192, 15, 12, 16, 93, 34, 6, 1766, 2, 33, 4, 2, 7, 15, 2, 2, 3286, 325, 12, 62, 30, 776, 8, 67, 14, 17, 6, 2, 44, 148, 687, 2, 203, 42, 203, 24, 28, 69, 2, 2, 11, 330, 54, 29, 93, 2, 21, 845, 2, 27, 1099, 7, 819, 4, 22, 1407, 17, 6, 2, 787, 7, 2460, 2, 2, 100, 30, 4, 3737, 3617, 3169, 2321, 42, 1898, 11, 4, 3814, 42, 101, 704, 7, 101, 999, 15, 1625, 94, 2926, 180, 5, 9, 2, 34, 2, 45, 6, 1429, 22, 60, 6, 1220, 31, 11, 94, 2, 96, 21, 94, 749, 9, 57, 975]),\n",
              "         ...,\n",
              "         list([1, 13, 1408, 15, 8, 135, 14, 9, 35, 32, 46, 394, 20, 62, 30, 2, 21, 45, 184, 78, 4, 1492, 910, 769, 2290, 2515, 395, 4257, 5, 1454, 11, 119, 2, 89, 1036, 4, 116, 218, 78, 21, 407, 100, 30, 128, 262, 15, 7, 185, 2280, 284, 1842, 2, 37, 315, 4, 226, 20, 272, 2942, 40, 29, 152, 60, 181, 8, 30, 50, 553, 362, 80, 119, 12, 21, 846, 2]),\n",
              "         list([1, 11, 119, 241, 9, 4, 840, 20, 12, 468, 15, 94, 3684, 562, 791, 39, 4, 86, 107, 8, 97, 14, 31, 33, 4, 2960, 7, 743, 46, 1028, 9, 3531, 5, 4, 768, 47, 8, 79, 90, 145, 164, 162, 50, 6, 501, 119, 7, 9, 4, 78, 232, 15, 16, 224, 11, 4, 333, 20, 4, 985, 200, 5, 2, 5, 9, 1861, 8, 79, 357, 4, 20, 47, 220, 57, 206, 139, 11, 12, 5, 55, 117, 212, 13, 1276, 92, 124, 51, 45, 1188, 71, 536, 13, 520, 14, 20, 6, 2302, 7, 470]),\n",
              "         list([1, 6, 52, 2, 430, 22, 9, 220, 2594, 8, 28, 2, 519, 3227, 6, 769, 15, 47, 6, 3482, 4067, 8, 114, 5, 33, 222, 31, 55, 184, 704, 2, 2, 19, 346, 3153, 5, 6, 364, 350, 4, 184, 2, 9, 133, 1810, 11, 2, 2, 21, 4, 2, 2, 570, 50, 2005, 2643, 9, 6, 1249, 17, 6, 2, 2, 21, 17, 6, 1211, 232, 1138, 2249, 29, 266, 56, 96, 346, 194, 308, 9, 194, 21, 29, 218, 1078, 19, 4, 78, 173, 7, 27, 2, 2, 3406, 718, 2, 9, 6, 2, 17, 210, 5, 3281, 2, 47, 77, 395, 14, 172, 173, 18, 2740, 2931, 4517, 82, 127, 27, 173, 11, 6, 392, 217, 21, 50, 9, 57, 65, 12, 2, 53, 40, 35, 390, 7, 11, 4, 3567, 7, 4, 314, 74, 6, 792, 22, 2, 19, 714, 727, 2, 382, 4, 91, 2, 439, 19, 14, 20, 9, 1441, 2, 1118, 4, 756, 25, 124, 4, 31, 12, 16, 93, 804, 34, 2005, 2643])],\n",
              "        dtype=object),\n",
              "  array([0, 1, 1, ..., 0, 0, 0])))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=500)"
      ],
      "metadata": {
        "id": "FELtC4EGlTy4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The output of this first layer would be a matrix with the size 32 * 500 for\n",
        "Embedding(5000, 32, input_length=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biGMi2Y7lomt",
        "outputId": "1e3d0080-ca81-40b3-af18-aefa0a2b6f38"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f7635e85ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, 32, input_length=max_words))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation= 'relu' ))\n",
        "model.add(Dense(1, activation= 'sigmoid' ))\n",
        "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[ 'accuracy'])\n",
        "print(model.summary())\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, verbose=1)\n",
        "# Final evaluation of the model\n",
        "scores_MLP = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy with MLP: %.2f%%\" % (scores_MLP[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsNhUComl2Ue",
        "outputId": "fda16602-f7b9-4006-dc6c-f5601206f00f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 16000)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 250)               4000250   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 251       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,160,501\n",
            "Trainable params: 4,160,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 0.3890 - accuracy: 0.8096 - val_loss: 0.2930 - val_accuracy: 0.8765\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.1218 - accuracy: 0.9556 - val_loss: 0.4070 - val_accuracy: 0.8566\n",
            "Accuracy with MLP: 85.66%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CNN-1D**"
      ],
      "metadata": {
        "id": "mJsPIWr66qN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Convolution1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence"
      ],
      "metadata": {
        "id": "8B0Q0R8U59wP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "test_split = 0.33\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "# pad dataset to a maximum review length in words\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "metadata": {
        "id": "3ljxkxSQ63zW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(top_words, 32, input_length= max_words))\n",
        "model.add(Convolution1D(filters=32, kernel_size=3, padding= 'same' ,activation= 'relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation= 'relu' ))\n",
        "model.add(Dense(1, activation= 'sigmoid' ))"
      ],
      "metadata": {
        "id": "eK0EN6-o66Al"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvN93sMw7Fbc",
        "outputId": "18f9752c-0eaf-4b07-e69b-77f7f916ba5c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 500, 32)           3104      \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 250, 32)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 8000)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 250)               2000250   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 251       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,163,605\n",
            "Trainable params: 2,163,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpnycNUO7zVt",
        "outputId": "44cbdbed-99ba-45a8-ce67-56903f99cc5c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "782/782 [==============================] - 45s 56ms/step - loss: 0.3681 - accuracy: 0.8203 - val_loss: 0.2761 - val_accuracy: 0.8844\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 50s 63ms/step - loss: 0.1964 - accuracy: 0.9237 - val_loss: 0.2923 - val_accuracy: 0.8801\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f762dfa3ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy with CNN: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb-ete1M76eH",
        "outputId": "5cea8cdd-1823-46a3-cadd-19a1ef664ff0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with CNN: 88.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "MXD75Daf8huw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rJHNYWne-hLy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}